--- https://ieeexplore.ieee.org/document/9703021 (ieee.explore) Deep Malware

Input Layer
Convolutional + ReLU 3x3x30
max-pooling 2x2
Convoltional + ReLU 3x3x15
max-pooling 2x2
Dropout
Flatten Layer
Fully-connected 
Dropout
Fully-connected 
Fully-connected 

--- https://ieeexplore.ieee.org/document/10474230 (ieee.explore) Classification of Malware using deep learning

Conv2D ReLU 32
Maxpooling2D
Conv2D ReLU 64
Maxpooling2D
Conv2D ReLU 128
Maxpooling2D
Conv2D
Maxpooling2D
Dropout 
Flatten
Dense 512
Dropout
Dense 512
Dense

--- https://ieeexplore.ieee.org/document/10085625 A survey on Malware Classification using Deep Learning Techniques, https://ieeexplore.ieee.org/document/8887303
SPP layer operates in between last convolutional layer and fully connected layer and divides feature maps from last convolutional layer into multiple levels and multiple subsections 

Input Layer
ResNet50
SPP [1,2,4] or
Flatten 
Dense 
BatchNormalization 
Activation 
Dropout
Dense
BatchNormalization 
Activation (sigmoid)

Input Layer
Conv 32 (3x3)
BatchNormalization 
Activation ReLU
Maxpooling (2x2)
Conv 64 (3x3)
BatchNormalization 
Activation ReLU
Maxpooling (2x2)
SPP [1,2,4] or
Flatten 
Dense (256)
BatchNormalization
Activation ReLU
Dropout
Dense
BatchNormalization
Activation (sigmoid)

---triplet network 

Input 
Convolution
Max pooling
BatchNormalization
Convolution
Max pooling 
Batch Normalization
Convolution
Max pooling
Batch Normalization
Convolution
Max pooling

--- https://ieeexplore.ieee.org/document/10256957 A comparison study to detect malware using Deep learning and Machine Learning techniques 

Input Layer relu 8 nodes input image 
Layer 10 nodes relu 
Layer 10 nodes relu 
Layer 10 nodes relu
Softmax

--- https://ieeexplore.ieee.org/document/10273961 Malware DetectÅŸon Based on Deep Learning

Conv 3x1x64
Conv 3x1x64
Conv 3x1x64
FC   128 

4L-DNN
FC layer 1024
FC layer 256
FC layer 64
FC layer 16

--- https://ieeexplore.ieee.org/document/9788424 Deep Learning Based Residual Attention Network for Malware Detection in CyberSecurity

non-linear residual kernel along with attention mechanism composite skip connections
residual layer
soft attention node
residual layer
soft attention node 
pooling 
Flatten 
fully connected layer - selft attention layer with residuals applicable to MBConv 

--- https://ieeexplore.ieee.org/document/9251181 AMC-MDL: A Novel Approach of Android Malware Classification using Multimodel Deep Learning
 
Input 
Attention Layer 
CNN
CNN Feature Abstract
GRU Layer
Softmax - GRU Network is used to replace pooling layer in the CNN network GRU simpler recurrent neural network than LSTM

--- https://ieeexplore.ieee.org/document/10393831 Migration Deep Learning Model (SeNet)

Conv2D-1
MaxPooling2D-1 
Conv2D-2
MaxPooling2D-2
Linear-1
Linear-2
Linear-3

--- https://ieeexplore.ieee.org/document/9579750 EfficientNet-based Convolution Neural Networks for Malware Classification

260x260 grayscale image normalization to image data into 0-1 range 299x299, 260x260, 224x224
EfficientNet-B1 model last layer adapted to attain malware family classification 
malware -> EfficientNet-B1 -> last layer of pre-trained model -> Global Average Pooling -> Malware Family 
EfficientNet-B1 
global_average_pooling2d_5 -> spp layer can be added 
dense (None, 9)

--- https://www.sciencedirect.com/science/article/pii/S0167404822001742 Deep learning based cross architecture internet of things malware detection and classification

byte sequences 
Input (27246XL)                      Input (9082 X L)
Preprocess (27246X2000)              Preprocess (9082 X 2000)
Embedded Layer (69,128,2000)         Bi -GRU - CNN model
Dropout Layer 0.1                    Dense(9, Softmax)
Conv1D (128,3,ReLu)
Maxpooling Layer (2)
Dropout Layer (0.1)
Bidirectional (GRU 128)
Dropout Layer 0.1 
Flatten Layer 
Dense (64, Relu)
Dropout Layer 

--- https://www.sciencedirect.com/science/article/pii/S2214212621002465 DTMIC: Deep transfer learning 

Grayscale images 
Build CNN architecture using Transfer Learning (single fully connected dense layer replaces last two dense layers)
Add fully connected layer of 128 neurons 
Add softmax layer for prediction of n families 

--- https://ieeexplore.ieee.org/document/10497315 Classification of Malware Families Using Transformers and Auto Formers in Deep Learning

Self attention mechanism can be used for 

--- https://ieeexplore.ieee.org/document/9498570 AE-DCNN: Autoencoder Enhanced Deep Convolutional Neural Network For Malware Classification 

Residual blocks are effective

--- https://ieeexplore.ieee.org/document/9616822 Visual Malware Classification Using Transfer Learning 

VGG19 is the best performing one we can use VGG19 layer architecture to MBConv

--- https://ieeexplore.ieee.org/document/10262691 Deep Learning techniques for malware detection A comprehensive survey 

static features can use CNN + LSTM 

--- https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9411822 A Multi Dimensional Deep Learning Framework for IoT Malware Classification and Family Attribution 

feature fusion over CNN outputs and LSTM outputs

--- https://ieeexplore.ieee.org/document/10441465 Empowering Android Malware Detection: A Deep Learning Ensemble with Optimal Features 

weighted ensemble classifier BiLSTM combine predictions of the individual models combining BiLSTM and CNN is the best 

--- https://ieeexplore.ieee.org/document/9842692 Exploring Optimal Deep Learning Models for Image-based Malware Variant Classification

EfficientNet-b3 16 batch size EfficientNet-b4 8 batch size 
EfficientNet-b4 frozen none numbers and names of frozen layers in keras / pytorch implementation 

--- https://www.sciencedirect.com/science/article/pii/S0950705124001783 CNN-LSTM
EfficientNetV2 CNN-LSTM model 

--- https://www.sciencedirect.com/science/article/pii/S1877050924005982 CNN-LSTM Hybrid Model for Enhanced Malware Analysis and Detection 

CNN-LSTM Hybrid

--- https://www.sciencedirect.com/science/article/pii/S1110016823011547#se0070 Using 3D-VGG-16 and 3D ResNet 18 Deep Learning Models and FABEMD techniques in the detection of malware 

VGG16 and ResNet18 feature fusion Feature Vector FABEMD techniques 

---  https://www.sciencedirect.com/science/article/pii/S016740482300295X new boosted CNN and ensemble learning based IoT malware classification

Prominent and diverse channels are achieved using STM blocks and TL to learn infection Deep Squezzed boosted and ensemble learning dilated convolutional 

--- https://www.sciencedirect.com/science/article/pii/S0167404822002401#sec0007 Ensemble of pretrained 

Transformer block BERT, CANINE the pretrained transformer models outperforms in classfiying highly unbalanced malware families 
